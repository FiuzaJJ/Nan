{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc11d645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['sample1', 4.61928175, 1.937171963, 1.052928098],\n",
       "       ['sample2', 5.782717628, 1.175901957, 1.214737524],\n",
       "       ['sample3', 3.953447633, 1.350473236, 2.132459339],\n",
       "       ['sample4', 2.038083652, 0.948045427, 1.380239621],\n",
       "       ['sample5', 4.978294553, 0.459765296, 2.539621518],\n",
       "       ['sample6', 4.262552834, 0.336063472, 1.55097026],\n",
       "       ['sample7', 7.819111584, 0.846057989, 0.785458041],\n",
       "       ['sample8', 9.390954184, 1.36481141, 1.676221842],\n",
       "       ['sample9', 6.713935235, 1.853940478, 2.054206282],\n",
       "       ['sample10', 8.779337413, 1.361967507, 1.81236406],\n",
       "       ['sample11', 8.605301328, 2.056711184, 0.823049343],\n",
       "       ['sample12', 11.47050932, 1.445822976, 2.123401956],\n",
       "       ['sample13', 10.62416263, 0.980751729, 1.429506685],\n",
       "       ['sample14', 8.608632725, 0.456044771, 1.905153587],\n",
       "       ['sample15', 4.775166356, 1.56874649, 1.777716209],\n",
       "       ['sample16', 5.416822914, 1.384659314, 1.306419633],\n",
       "       ['sample17', 5.98264914, 2.058122288, 2.444016043],\n",
       "       ['sample18', 2.916752227, 1.096151139, 2.719215459],\n",
       "       ['sample19', 4.015615107, 1.141398409, 0.81211405],\n",
       "       ['sample20', 7.864814361, 0.418792333, 1.779742335],\n",
       "       ['sample21', 7.033602196, 1.113413792, 2.622974159],\n",
       "       ['sample22', 4.634440368, 1.210679183, 1.468448415],\n",
       "       ['sample23', 11.76384273, 0.644607861, 2.039251512],\n",
       "       ['sample24', 7.066639266, 1.765153948, 1.707615049],\n",
       "       ['sample25', 5.287322115, 1.495988644, 2.19346639],\n",
       "       ['sample26', 9.048044943, 1.532648149, 0.528092684],\n",
       "       ['sample27', 3.601339618, 2.111611554, 1.946483299],\n",
       "       ['sample28', 11.66420276, 0.932016646, 1.361377016],\n",
       "       ['sample29', 11.40988742, 0.646382307, 2.183103525],\n",
       "       ['sample30', 8.323230305, 0.766223753, 1.953846504],\n",
       "       ['sample31', 8.757543179, 0.409188192, 2.076762628],\n",
       "       ['sample32', 9.85280872, 0.909284834, 0.410575639],\n",
       "       ['sample33', 11.88990894, 0.452401992, 1.899744887],\n",
       "       ['sample34', 2.72021257, 1.002508987, 2.015514211],\n",
       "       ['sample35', 7.765041178, 2.090765622, 0.717669024],\n",
       "       ['sample36', 4.754771254, 0.743623766, 1.907755626],\n",
       "       ['sample37', 4.529409949, 1.483695552, 2.061256394],\n",
       "       ['sample38', 5.32125667, 0.972232251, 0.564364225],\n",
       "       ['sample39', 11.32821111, 0.324832342, 0.942180655],\n",
       "       ['sample40', 8.83188842, 0.96871635, 2.299744407],\n",
       "       ['sample41', 9.003231708, 1.332577845, 0.871241114],\n",
       "       ['sample42', 6.932242422, 1.616133429, 2.09378596],\n",
       "       ['sample43', 7.820476497, 0.375500301, 1.633673993],\n",
       "       ['sample44', 7.338057651, 1.258756301, 2.685524395],\n",
       "       ['sample45', 8.254937635, 0.621686537, 0.814903787],\n",
       "       ['sample46', 1.993670939, 1.370442284, 1.366220338],\n",
       "       ['sample47', 1.655542573, 1.035475455, 0.589628905],\n",
       "       ['sample48', 9.868011876, 1.760324167, 1.137508224],\n",
       "       ['sample49', 3.443047506, 1.746169763, 2.342494262],\n",
       "       ['sample50', 6.330234974, 1.905855589, 1.15934608],\n",
       "       ['sample51', 10.50077037, 0.820374652, 0.445271672],\n",
       "       ['sample52', 5.755955583, 1.847121633, 0.837569566],\n",
       "       ['sample53', 11.88797447, 0.276526487, 0.487412159],\n",
       "       ['sample54', 6.603201211, 1.390827525, 2.180057692],\n",
       "       ['sample55', 5.005836632, 1.926723823, 1.247651648],\n",
       "       ['sample56', 2.948547794, 0.433674598, 0.634968857],\n",
       "       ['sample57', 9.295636797, 0.753270341, 2.488333994],\n",
       "       ['sample58', 4.223791285, 1.047263814, 1.166746025],\n",
       "       ['sample59', 8.091502065, 1.468935099, 2.434180654],\n",
       "       ['sample60', 3.666153008, 2.030915378, 2.48869294],\n",
       "       ['sample61', 10.07431357, 0.802522056, 0.812701183],\n",
       "       ['sample62', 4.394222716, 0.659493706, 1.662270396],\n",
       "       ['sample63', 8.163043734, 0.45431069, 1.743255994],\n",
       "       ['sample64', 1.755238845, 1.431043461, 1.456552867],\n",
       "       ['sample65', 11.06393642, 0.844180184, 2.434447954],\n",
       "       ['sample66', 11.0758554, 0.40679548, 1.392430908],\n",
       "       ['sample67', 2.57610017, 1.276957124, 1.343514099],\n",
       "       ['sample68', 4.649410822, 0.389770855, 1.620010208],\n",
       "       ['sample69', 7.884870359, 1.224948299, 1.641199843],\n",
       "       ['sample70', 2.083603508, 1.487109953, 0.745591806],\n",
       "       ['sample71', 8.085028116, 1.992767186, 1.996857825],\n",
       "       ['sample72', 7.703643745, 0.421729745, 2.664529964],\n",
       "       ['sample73', 3.272484163, 2.023931476, 2.462034892],\n",
       "       ['sample74', 7.080100402, 1.204923332, 2.470078267],\n",
       "       ['sample75', 11.85514049, 0.44591536, 0.65675043],\n",
       "       ['sample76', 9.704684769, 1.132047332, 2.23542345],\n",
       "       ['sample77', 2.717045528, 0.647646793, 0.581811139],\n",
       "       ['sample78', 5.21982291, 0.31594611, 1.403038359],\n",
       "       ['sample79', 7.429750182, 1.659416417, 1.557944343],\n",
       "       ['sample80', 7.881889784, 1.845940127, 0.837097945],\n",
       "       ['sample81', 3.984727309, 1.353590479, 1.999677845],\n",
       "       ['sample82', 6.370350319, 1.926515908, 1.489260905],\n",
       "       ['sample83', 5.884311303, 2.016112571, 0.776661735],\n",
       "       ['sample84', 11.46373843, 0.787344997, 1.927658309],\n",
       "       ['sample85', 8.083123049, 0.529369135, 1.450910721],\n",
       "       ['sample86', 9.207386254, 2.009388346, 1.575640308],\n",
       "       ['sample87', 11.00470205, 1.981495167, 0.409987961],\n",
       "       ['sample88', 3.36731976, 0.846337731, 2.356409351],\n",
       "       ['sample89', 5.719336358, 0.968393449, 0.434602716],\n",
       "       ['sample90', 2.371493507, 1.454219747, 1.969092896],\n",
       "       ['sample91', 11.42393065, 0.467686271, 0.429930422],\n",
       "       ['sample92', 6.278530564, 0.470864597, 1.723416514],\n",
       "       ['sample93', 9.52075699, 1.22403262, 2.479239854],\n",
       "       ['sample94', 6.531088956, 1.762051407, 1.429379632],\n",
       "       ['sample95', 3.369372452, 1.400029125, 2.647925088],\n",
       "       ['sample96', 5.893707959, 1.898131282, 1.406329092],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan]], dtype=object)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "#transfer_plate=pd.read_csv(\"test/transfer_plate.csv\",header=0)\n",
    "arr = pd.read_csv(\"test/transfer_plate.csv\").iloc[:, 1:-4].to_numpy()#I don't know what is up with the last collumn but it shouldnt matter if the convulution isnt padded.\n",
    "transfer_plate_labels=pd.read_csv(\"test/transfer_plate.csv\").iloc[:, -4:].to_numpy()\n",
    "test_data = pd.read_csv(\"test/96_samples.csv\",header=None).iloc[:, 1:].to_numpy()\n",
    "\n",
    "csv_files = glob.glob(\"*.csv\")\n",
    "dataframes = {}\n",
    "for file in csv_files:\n",
    "    \n",
    "    dataframes[file] = pd.read_csv(file)\n",
    "    \n",
    "\n",
    "\n",
    "transfer_plate_labels#here i will assume that the these samples are well placed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5fc39634",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_plate_labels_1=[]\n",
    "for i in range(len(transfer_plate_labels)-1):\n",
    "    \n",
    "    transfer_plate_labels_1.append(transfer_plate_labels[i])\n",
    "    transfer_plate_labels_1.append(transfer_plate_labels[i])\n",
    "  \n",
    "transfer_plate_labels_1=np.array(transfer_plate_labels_1)[:192,-3:]\n",
    "transfer_plate_labels_1=np.array(transfer_plate_labels_1,dtype=np.float32)\n",
    "\n",
    "#oogga boogga data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8f9dca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anton_532.csv\n",
      "[[6.12906223e-01 6.18048921e-01 6.01548923e-01 ... 1.17462023e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.04361960e-01 6.11595483e-01 5.97326514e-01 ... 1.17462023e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.01281558e-01 6.09306579e-01 5.95375892e-01 ... 1.17462023e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.31933961e-01 6.37724692e-01 6.22076512e-01 ... 2.83731990e-04\n",
      "  0.00000000e+00 3.26054705e-04]\n",
      " [6.32346420e-01 6.36125394e-01 6.20006880e-01 ... 2.83731990e-04\n",
      "  0.00000000e+00 3.26054705e-04]\n",
      " [6.29817051e-01 6.35774885e-01 6.20083503e-01 ... 2.83731990e-04\n",
      "  0.00000000e+00 3.26054705e-04]]\n",
      "anton_785.csv\n",
      "[[3.30425459e-01 3.28524414e-01 3.25652804e-01 ... 5.27940930e-07\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.30246520e-01 3.26422957e-01 3.23595724e-01 ... 5.27940930e-07\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.27078588e-01 3.25612722e-01 3.24311479e-01 ... 5.27940930e-07\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.16342835e-01 4.81799065e-01 4.48261646e-01 ... 4.98278609e-04\n",
      "  0.00000000e+00 5.72604046e-04]\n",
      " [5.18656156e-01 4.82584964e-01 4.49295196e-01 ... 4.98278609e-04\n",
      "  0.00000000e+00 5.72604046e-04]\n",
      " [5.16610528e-01 4.82836909e-01 4.49797656e-01 ... 4.98278609e-04\n",
      "  0.00000000e+00 5.72604046e-04]]\n",
      "kaiser.csv\n",
      "[[9.25531148e-04 9.12771980e-04 9.02595024e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.91712634e-04 9.97931389e-04 1.00364978e-03 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.64772772e-04 7.65478636e-04 7.65165911e-04 ... 0.00000000e+00\n",
      "  8.93499202e-05 0.00000000e+00]\n",
      " ...\n",
      " [7.24806553e-04 7.31445252e-04 7.37172581e-04 ... 4.32006864e-06\n",
      "  0.00000000e+00 3.57399681e-04]\n",
      " [7.54703036e-04 7.54962151e-04 7.53228762e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 3.57399681e-04]\n",
      " [9.66346192e-04 9.66775071e-04 9.67016316e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 3.57399681e-04]]\n",
      "metrohm.csv\n",
      "[[6.22765720e-01 6.06248005e-01 5.92483243e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.13788701e-01 6.00702202e-01 5.82229492e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.13589212e-01 6.01739547e-01 5.82907756e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.56878391e-01 1.55003192e-01 1.53686562e-01 ... 9.75542611e-07\n",
      "  3.98978615e-05 1.59591446e-04]\n",
      " [1.59072774e-01 1.55880945e-01 1.55442068e-01 ... 9.75542611e-07\n",
      "  3.98978615e-05 1.59591446e-04]\n",
      " [1.59671242e-01 1.55801149e-01 1.52649218e-01 ... 9.75542611e-07\n",
      "  3.98978615e-05 1.59591446e-04]]\n",
      "mettler_toledo.csv\n",
      "[[1.96661941e-01 1.97845222e-01 1.98576103e-01 ... 6.14731083e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.94939308e-01 1.94607325e-01 1.95538305e-01 ... 6.14731083e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.97620113e-01 1.98136566e-01 1.98189601e-01 ... 6.14731083e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.03829308e-01 2.04063400e-01 2.04661019e-01 ... 9.17358949e-08\n",
      "  0.00000000e+00 7.31546211e-05]\n",
      " [2.03758309e-01 2.04398978e-01 2.04769295e-01 ... 9.17358949e-08\n",
      "  0.00000000e+00 7.31546211e-05]\n",
      " [2.02295463e-01 2.01919619e-01 2.02225616e-01 ... 9.17358949e-08\n",
      "  0.00000000e+00 7.31546211e-05]]\n",
      "tec5.csv\n",
      "[[3.79402626e-04 4.83311281e-04 5.78609714e-04 ... 3.05152582e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.06524439e-04 5.06217247e-04 5.93625425e-04 ... 3.05152582e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.79402626e-04 4.83311281e-04 5.78609714e-04 ... 3.05152582e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.67053021e-04 4.60229474e-04 5.43578008e-04 ... 3.73152857e-05\n",
      "  0.00000000e+00 9.18705370e-05]\n",
      " [4.11883041e-04 5.06155694e-04 5.86927006e-04 ... 3.73152857e-05\n",
      "  0.00000000e+00 9.18705370e-05]\n",
      " [3.33739845e-04 4.37393858e-04 5.36107946e-04 ... 3.73152857e-05\n",
      "  0.00000000e+00 9.18705370e-05]]\n",
      "timegate.csv\n",
      "[[1.51508270e-04 1.45024022e-04 1.39042930e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.16959676e-04 2.11524166e-04 1.99442466e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00852137e-04 9.69667272e-05 9.38503920e-05 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.55558012e-04 2.47829023e-04 2.35805287e-04 ... 0.00000000e+00\n",
      "  5.97571470e-02 2.39028588e-01]\n",
      " [3.03039846e-04 2.90354001e-04 2.79622215e-04 ... 8.83115021e-02\n",
      "  0.00000000e+00 2.39028588e-01]\n",
      " [1.56702959e-04 1.51954656e-04 1.45659241e-04 ... 1.35104934e-03\n",
      "  5.97571470e-02 2.39028588e-01]]\n",
      "tornado.csv\n",
      "[[3.33131201e-01 3.32603581e-01 3.31909517e-01 ... 4.64230071e-08\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.35422392e-01 3.32590688e-01 3.30247637e-01 ... 4.64230071e-08\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.37374578e-01 3.35245580e-01 3.32316435e-01 ... 4.64230071e-08\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.16243535e-01 2.15436811e-01 2.14581300e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 4.37128127e-05]\n",
      " [2.16080576e-01 2.14889425e-01 2.13959521e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 4.37128127e-05]\n",
      " [2.16917289e-01 2.16455864e-01 2.15927146e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 4.37128127e-05]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "target_wavenumbers = np.linspace(300, 1942, 1340)\n",
    "interpolated = []\n",
    "conc=[]\n",
    "\n",
    "for file in csv_files:\n",
    "    # Convert column names to float\n",
    "    print(file)\n",
    "    wavelengths = dataframes[file].columns[:-5].astype(float)\n",
    "    # Get only the spectral data\n",
    "    intensities_y = (dataframes[file].values)\n",
    "\n",
    "    conc.append(intensities_y[:,-5:-2])\n",
    "    #normalization steps --1-- scaling\n",
    "    \n",
    "    intensities_y=intensities_y/(np.max(intensities_y))\n",
    "\n",
    "    print(intensities_y)\n",
    "\n",
    "    # Interpolate each row (spectrum)\n",
    "    \n",
    "    for row in intensities_y:\n",
    "        \n",
    "        f = interp1d(wavelengths, row[:-5], kind='quadratic', fill_value='extrapolate')\n",
    "\n",
    "        interpolated.append(f(target_wavenumbers))\n",
    "        \n",
    "    \n",
    "\n",
    "interpolated=np.array(interpolated)\n",
    "\n",
    "#normalization step --2--\n",
    "\n",
    "interpolated=(interpolated-np.mean(interpolated))/np.std(interpolated)\n",
    "\n",
    "conc=np.vstack(conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43063b",
   "metadata": {},
   "source": [
    "Now we standardize the weird ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b7d949c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 2046)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "arr=arr[:,1:-1]/np.max(arr[:,1:-1])#here, the original array has \"[\" \"]\" and are strings, fix \n",
    "\n",
    "test_data=test_data[:,1:-1]/np.max(test_data[:,1:-1])\n",
    "np.shape(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da0c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  65.        ,   66.60635697,   68.21271394, ..., 3346.78728606,\n",
       "       3348.39364303, 3350.        ])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelengths=np.linspace(65,3350,2046)# fix with fix up\n",
    "\n",
    "\n",
    "transfer_plate=[]\n",
    "clean_test=[]\n",
    "for row in arr:\n",
    "\n",
    "    \n",
    "    f = interp1d(wavelengths, row, kind='quadratic', fill_value='extrapolate')\n",
    "    transfer_plate.append(f(target_wavenumbers))\n",
    "\n",
    "for row in test_data:\n",
    "    g = interp1d(wavelengths, row, kind='quadratic', fill_value='extrapolate')\n",
    "    \n",
    "    clean_test.append(g(target_wavenumbers))\n",
    "\n",
    "\n",
    "transfer_plate=(transfer_plate-np.mean(transfer_plate))/np.std(transfer_plate)\n",
    "clean_test=(clean_test-np.mean(clean_test))/np.std(clean_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3584081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import importlib\n",
    "import Data_augment\n",
    "importlib.reload(Data_augment)\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from Data_augment import sinusoidal_noise ,left_right_shift \n",
    "\n",
    "\n",
    "\n",
    "class RamanDataset(Dataset):\n",
    "    def __init__(self, spectra, targets, train=True):\n",
    "\n",
    "        if isinstance(spectra, np.ndarray) and spectra.dtype == object:\n",
    "            spectra = np.stack(spectra)  # fix object array\n",
    "        self.spectra = torch.tensor(spectra, dtype=torch.float32)\n",
    "        \n",
    "\n",
    "        self.targets = None if targets is None else torch.tensor(targets, dtype=torch.float32)\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Add channel dimension for CNN: (C, L) where C=1 for 1D signal\n",
    "        spectrum = self.spectra[idx].unsqueeze(0)  \n",
    "        \n",
    "        if self.targets is not None:\n",
    "            target = self.targets[idx]\n",
    "\n",
    "\n",
    "        # #data augmentation steps\n",
    "        # if self.train:\n",
    "        #     #cosign augmentation\n",
    "        #     spectrum = spectrum + sinusoidal_noise(1340)\n",
    "        #     spectrum = left_right_shift(torch.linspace(300,1940,1340),spectrum,5)\n",
    "\n",
    "        if self.targets is not None:\n",
    "            target = self.targets[idx]\n",
    "            return spectrum, target\n",
    "        \n",
    "        else:\n",
    "            return spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0a43f5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.619282    1.9371719   1.0529281 ]\n",
      " [ 4.619282    1.9371719   1.0529281 ]\n",
      " [ 5.7827177   1.175902    1.2147375 ]\n",
      " [ 5.7827177   1.175902    1.2147375 ]\n",
      " [ 3.9534476   1.3504733   2.1324594 ]\n",
      " [ 3.9534476   1.3504733   2.1324594 ]\n",
      " [ 2.0380836   0.94804543  1.3802396 ]\n",
      " [ 2.0380836   0.94804543  1.3802396 ]\n",
      " [ 4.9782944   0.4597653   2.5396216 ]\n",
      " [ 4.9782944   0.4597653   2.5396216 ]\n",
      " [ 4.2625527   0.33606347  1.5509703 ]\n",
      " [ 4.2625527   0.33606347  1.5509703 ]\n",
      " [ 7.8191113   0.846058    0.785458  ]\n",
      " [ 7.8191113   0.846058    0.785458  ]\n",
      " [ 9.390954    1.3648114   1.6762218 ]\n",
      " [ 9.390954    1.3648114   1.6762218 ]\n",
      " [ 6.7139354   1.8539405   2.0542064 ]\n",
      " [ 6.7139354   1.8539405   2.0542064 ]\n",
      " [ 8.779338    1.3619676   1.8123641 ]\n",
      " [ 8.779338    1.3619676   1.8123641 ]\n",
      " [ 8.605301    2.0567112   0.82304937]\n",
      " [ 8.605301    2.0567112   0.82304937]\n",
      " [11.47051     1.445823    2.1234019 ]\n",
      " [11.47051     1.445823    2.1234019 ]\n",
      " [10.624163    0.98075175  1.4295067 ]\n",
      " [10.624163    0.98075175  1.4295067 ]\n",
      " [ 8.608633    0.45604476  1.9051536 ]\n",
      " [ 8.608633    0.45604476  1.9051536 ]\n",
      " [ 4.7751665   1.5687464   1.7777162 ]\n",
      " [ 4.7751665   1.5687464   1.7777162 ]\n",
      " [ 5.416823    1.3846593   1.3064196 ]\n",
      " [ 5.416823    1.3846593   1.3064196 ]\n",
      " [ 5.9826493   2.0581224   2.444016  ]\n",
      " [ 5.9826493   2.0581224   2.444016  ]\n",
      " [ 2.9167523   1.0961511   2.7192154 ]\n",
      " [ 2.9167523   1.0961511   2.7192154 ]\n",
      " [ 4.015615    1.1413984   0.81211406]\n",
      " [ 4.015615    1.1413984   0.81211406]\n",
      " [ 7.8648143   0.41879234  1.7797424 ]\n",
      " [ 7.8648143   0.41879234  1.7797424 ]\n",
      " [ 7.033602    1.1134138   2.6229742 ]\n",
      " [ 7.033602    1.1134138   2.6229742 ]\n",
      " [ 4.6344404   1.2106792   1.4684484 ]\n",
      " [ 4.6344404   1.2106792   1.4684484 ]\n",
      " [11.763843    0.64460784  2.0392516 ]\n",
      " [11.763843    0.64460784  2.0392516 ]\n",
      " [ 7.0666394   1.765154    1.707615  ]\n",
      " [ 7.0666394   1.765154    1.707615  ]\n",
      " [ 5.287322    1.4959886   2.1934664 ]\n",
      " [ 5.287322    1.4959886   2.1934664 ]\n",
      " [ 9.048045    1.5326482   0.5280927 ]\n",
      " [ 9.048045    1.5326482   0.5280927 ]\n",
      " [ 3.6013396   2.1116116   1.9464833 ]\n",
      " [ 3.6013396   2.1116116   1.9464833 ]\n",
      " [11.664203    0.9320167   1.361377  ]\n",
      " [11.664203    0.9320167   1.361377  ]\n",
      " [11.409887    0.64638233  2.1831036 ]\n",
      " [11.409887    0.64638233  2.1831036 ]\n",
      " [ 8.323231    0.7662237   1.9538465 ]\n",
      " [ 8.323231    0.7662237   1.9538465 ]\n",
      " [ 8.757544    0.40918818  2.0767627 ]\n",
      " [ 8.757544    0.40918818  2.0767627 ]\n",
      " [ 9.852809    0.90928483  0.41057563]\n",
      " [ 9.852809    0.90928483  0.41057563]\n",
      " [11.889909    0.452402    1.8997449 ]\n",
      " [11.889909    0.452402    1.8997449 ]\n",
      " [ 2.7202125   1.002509    2.0155141 ]\n",
      " [ 2.7202125   1.002509    2.0155141 ]\n",
      " [ 7.7650414   2.0907657   0.717669  ]\n",
      " [ 7.7650414   2.0907657   0.717669  ]\n",
      " [ 4.754771    0.7436238   1.9077556 ]\n",
      " [ 4.754771    0.7436238   1.9077556 ]\n",
      " [ 4.52941     1.4836955   2.0612564 ]\n",
      " [ 4.52941     1.4836955   2.0612564 ]\n",
      " [ 5.3212566   0.9722322   0.56436425]\n",
      " [ 5.3212566   0.9722322   0.56436425]\n",
      " [11.328211    0.32483235  0.94218063]\n",
      " [11.328211    0.32483235  0.94218063]\n",
      " [ 8.831888    0.9687163   2.2997444 ]\n",
      " [ 8.831888    0.9687163   2.2997444 ]\n",
      " [ 9.003232    1.3325778   0.8712411 ]\n",
      " [ 9.003232    1.3325778   0.8712411 ]\n",
      " [ 6.9322424   1.6161335   2.093786  ]\n",
      " [ 6.9322424   1.6161335   2.093786  ]\n",
      " [ 7.8204765   0.3755003   1.633674  ]\n",
      " [ 7.8204765   0.3755003   1.633674  ]\n",
      " [ 7.3380575   1.2587563   2.6855245 ]\n",
      " [ 7.3380575   1.2587563   2.6855245 ]\n",
      " [ 8.254937    0.6216865   0.8149038 ]\n",
      " [ 8.254937    0.6216865   0.8149038 ]\n",
      " [ 1.993671    1.3704423   1.3662204 ]\n",
      " [ 1.993671    1.3704423   1.3662204 ]\n",
      " [ 1.6555426   1.0354755   0.5896289 ]\n",
      " [ 1.6555426   1.0354755   0.5896289 ]\n",
      " [ 9.868011    1.7603241   1.1375083 ]\n",
      " [ 9.868011    1.7603241   1.1375083 ]\n",
      " [ 3.4430475   1.7461698   2.3424942 ]\n",
      " [ 3.4430475   1.7461698   2.3424942 ]\n",
      " [ 6.330235    1.9058555   1.1593461 ]\n",
      " [ 6.330235    1.9058555   1.1593461 ]\n",
      " [10.500771    0.82037467  0.44527167]\n",
      " [10.500771    0.82037467  0.44527167]\n",
      " [ 5.7559557   1.8471216   0.8375696 ]\n",
      " [ 5.7559557   1.8471216   0.8375696 ]\n",
      " [11.887975    0.27652648  0.48741215]\n",
      " [11.887975    0.27652648  0.48741215]\n",
      " [ 6.6032014   1.3908275   2.1800578 ]\n",
      " [ 6.6032014   1.3908275   2.1800578 ]\n",
      " [ 5.0058365   1.9267238   1.2476517 ]\n",
      " [ 5.0058365   1.9267238   1.2476517 ]\n",
      " [ 2.9485478   0.4336746   0.6349689 ]\n",
      " [ 2.9485478   0.4336746   0.6349689 ]\n",
      " [ 9.295637    0.7532703   2.488334  ]\n",
      " [ 9.295637    0.7532703   2.488334  ]\n",
      " [ 4.223791    1.0472639   1.166746  ]\n",
      " [ 4.223791    1.0472639   1.166746  ]\n",
      " [ 8.091502    1.4689351   2.4341807 ]\n",
      " [ 8.091502    1.4689351   2.4341807 ]\n",
      " [ 3.666153    2.0309153   2.488693  ]\n",
      " [ 3.666153    2.0309153   2.488693  ]\n",
      " [10.074313    0.80252206  0.81270117]\n",
      " [10.074313    0.80252206  0.81270117]\n",
      " [ 4.3942227   0.6594937   1.6622704 ]\n",
      " [ 4.3942227   0.6594937   1.6622704 ]\n",
      " [ 8.163044    0.4543107   1.743256  ]\n",
      " [ 8.163044    0.4543107   1.743256  ]\n",
      " [ 1.7552389   1.4310435   1.4565529 ]\n",
      " [ 1.7552389   1.4310435   1.4565529 ]\n",
      " [11.063936    0.84418017  2.434448  ]\n",
      " [11.063936    0.84418017  2.434448  ]\n",
      " [11.075855    0.40679547  1.3924309 ]\n",
      " [11.075855    0.40679547  1.3924309 ]\n",
      " [ 2.5761      1.2769572   1.3435141 ]\n",
      " [ 2.5761      1.2769572   1.3435141 ]\n",
      " [ 4.6494107   0.38977087  1.6200103 ]\n",
      " [ 4.6494107   0.38977087  1.6200103 ]\n",
      " [ 7.8848705   1.2249483   1.6411998 ]\n",
      " [ 7.8848705   1.2249483   1.6411998 ]\n",
      " [ 2.0836036   1.4871099   0.7455918 ]\n",
      " [ 2.0836036   1.4871099   0.7455918 ]\n",
      " [ 8.085028    1.9927672   1.9968579 ]\n",
      " [ 8.085028    1.9927672   1.9968579 ]\n",
      " [ 7.703644    0.42172974  2.66453   ]\n",
      " [ 7.703644    0.42172974  2.66453   ]\n",
      " [ 3.272484    2.0239315   2.462035  ]\n",
      " [ 3.272484    2.0239315   2.462035  ]\n",
      " [ 7.0801005   1.2049234   2.4700782 ]\n",
      " [ 7.0801005   1.2049234   2.4700782 ]\n",
      " [11.855141    0.44591537  0.65675044]\n",
      " [11.855141    0.44591537  0.65675044]\n",
      " [ 9.704685    1.1320473   2.2354236 ]\n",
      " [ 9.704685    1.1320473   2.2354236 ]\n",
      " [ 2.7170455   0.6476468   0.58181113]\n",
      " [ 2.7170455   0.6476468   0.58181113]\n",
      " [ 5.219823    0.3159461   1.4030384 ]\n",
      " [ 5.219823    0.3159461   1.4030384 ]\n",
      " [ 7.42975     1.6594164   1.5579443 ]\n",
      " [ 7.42975     1.6594164   1.5579443 ]\n",
      " [ 7.88189     1.8459401   0.83709794]\n",
      " [ 7.88189     1.8459401   0.83709794]\n",
      " [ 3.9847274   1.3535905   1.9996779 ]\n",
      " [ 3.9847274   1.3535905   1.9996779 ]\n",
      " [ 6.3703504   1.9265159   1.4892609 ]\n",
      " [ 6.3703504   1.9265159   1.4892609 ]\n",
      " [ 5.884311    2.0161126   0.77666175]\n",
      " [ 5.884311    2.0161126   0.77666175]\n",
      " [11.463738    0.787345    1.9276583 ]\n",
      " [11.463738    0.787345    1.9276583 ]\n",
      " [ 8.083123    0.5293691   1.4509107 ]\n",
      " [ 8.083123    0.5293691   1.4509107 ]\n",
      " [ 9.207386    2.0093884   1.5756403 ]\n",
      " [ 9.207386    2.0093884   1.5756403 ]\n",
      " [11.004702    1.9814951   0.40998796]\n",
      " [11.004702    1.9814951   0.40998796]\n",
      " [ 3.3673198   0.84633774  2.3564093 ]\n",
      " [ 3.3673198   0.84633774  2.3564093 ]\n",
      " [ 5.7193365   0.96839345  0.4346027 ]\n",
      " [ 5.7193365   0.96839345  0.4346027 ]\n",
      " [ 2.3714936   1.4542197   1.9690928 ]\n",
      " [ 2.3714936   1.4542197   1.9690928 ]\n",
      " [11.423931    0.46768627  0.42993042]\n",
      " [11.423931    0.46768627  0.42993042]\n",
      " [ 6.2785306   0.4708646   1.7234166 ]\n",
      " [ 6.2785306   0.4708646   1.7234166 ]\n",
      " [ 9.520757    1.2240326   2.47924   ]\n",
      " [ 9.520757    1.2240326   2.47924   ]\n",
      " [ 6.531089    1.7620515   1.4293796 ]\n",
      " [ 6.531089    1.7620515   1.4293796 ]\n",
      " [ 3.3693724   1.4000292   2.6479251 ]\n",
      " [ 3.3693724   1.4000292   2.6479251 ]\n",
      " [ 5.8937078   1.8981313   1.406329  ]\n",
      " [ 5.8937078   1.8981313   1.406329  ]]\n",
      "torch.Size([32, 1, 1340])\n",
      "torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "#dataset = RamanDataset(interpolated, conc , train=True)\n",
    "print(transfer_plate_labels_1)\n",
    "transfer_plate=np.array(transfer_plate,dtype=np.float32)\n",
    "\n",
    "dataset = RamanDataset(transfer_plate, transfer_plate_labels_1 , train=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Example: iterate\n",
    "for spectra_batch, targets_batch in loader:\n",
    "    print(spectra_batch.shape)  # (batch_size, 1, num_points)\n",
    "    \n",
    "    print(targets_batch.shape)  # (batch_size, 3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "909bba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SimpleRamanCNN(nn.Module):\n",
    "    def __init__(self, input_length=1340, num_outputs=3):\n",
    "        super(SimpleRamanCNN, self).__init__()\n",
    "        \n",
    "        # Article CNN\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=9, padding=4)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=7, padding=3)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, padding=2)\n",
    "        \n",
    "        # Global average pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, num_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch, 1, input_length)\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        x = self.global_avg_pool(x)  # Shape: (batch, channels, 1)\n",
    "        x = torch.flatten(x, 1)      # Shape: (batch, channels)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2ff3f574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 0: Loss 12.358452081680298\n",
      "1\n",
      "Epoch 1: Loss 7.424372951189677\n",
      "2\n",
      "Epoch 2: Loss 5.146110653877258\n",
      "3\n",
      "Epoch 3: Loss 4.3405139446258545\n",
      "4\n",
      "Epoch 4: Loss 3.845634619394938\n",
      "5\n",
      "Epoch 5: Loss 3.2213766972223916\n",
      "6\n",
      "Epoch 6: Loss 3.2556494077046714\n",
      "7\n",
      "Epoch 7: Loss 3.1901586850484214\n",
      "8\n",
      "Epoch 8: Loss 3.1428556044896445\n",
      "9\n",
      "Epoch 9: Loss 3.1068719228108725\n",
      "10\n",
      "Epoch 10: Loss 3.060161908467611\n",
      "11\n",
      "Epoch 11: Loss 3.1248390674591064\n",
      "12\n",
      "Epoch 12: Loss 3.1968791087468467\n",
      "13\n",
      "Epoch 13: Loss 3.1952839692433677\n",
      "14\n",
      "Epoch 14: Loss 3.0997872352600098\n",
      "15\n",
      "Epoch 15: Loss 3.2008931835492453\n",
      "16\n",
      "Epoch 16: Loss 3.118456721305847\n",
      "17\n",
      "Epoch 17: Loss 3.0602922439575195\n",
      "18\n",
      "Epoch 18: Loss 3.1340326070785522\n",
      "19\n",
      "Epoch 19: Loss 3.061172882715861\n",
      "20\n",
      "Epoch 20: Loss 3.0988367398579917\n",
      "21\n",
      "Epoch 21: Loss 3.0704523722330728\n",
      "22\n",
      "Epoch 22: Loss 3.2253373861312866\n",
      "23\n",
      "Epoch 23: Loss 3.1420545975367227\n",
      "24\n",
      "Epoch 24: Loss 3.045178850491842\n",
      "25\n",
      "Epoch 25: Loss 3.101846138636271\n",
      "26\n",
      "Epoch 26: Loss 3.2325831254323325\n",
      "27\n",
      "Epoch 27: Loss 3.118512749671936\n",
      "28\n",
      "Epoch 28: Loss 3.101346810658773\n",
      "29\n",
      "Epoch 29: Loss 3.127962589263916\n",
      "30\n",
      "Epoch 30: Loss 3.225079615910848\n",
      "31\n",
      "Epoch 31: Loss 3.5620030959447226\n",
      "32\n",
      "Epoch 32: Loss 3.5605801343917847\n",
      "33\n",
      "Epoch 33: Loss 3.287497798601786\n",
      "34\n",
      "Epoch 34: Loss 3.2405696312586465\n",
      "35\n",
      "Epoch 35: Loss 3.1507126490275064\n",
      "36\n",
      "Epoch 36: Loss 3.1498802502950034\n",
      "37\n",
      "Epoch 37: Loss 3.08820633093516\n",
      "38\n",
      "Epoch 38: Loss 3.140785733858744\n",
      "39\n",
      "Epoch 39: Loss 3.052766720453898\n",
      "40\n",
      "Epoch 40: Loss 3.117875059445699\n",
      "41\n",
      "Epoch 41: Loss 3.0581586360931396\n",
      "42\n",
      "Epoch 42: Loss 3.143256584803263\n",
      "43\n",
      "Epoch 43: Loss 3.070902864138285\n",
      "44\n",
      "Epoch 44: Loss 3.0933885176976523\n",
      "45\n",
      "Epoch 45: Loss 3.1087931394577026\n",
      "46\n",
      "Epoch 46: Loss 3.135121782620748\n",
      "47\n",
      "Epoch 47: Loss 3.1102426449457803\n",
      "48\n",
      "Epoch 48: Loss 3.132584532101949\n",
      "49\n",
      "Epoch 49: Loss 3.0880042711893716\n",
      "50\n",
      "Epoch 50: Loss 3.112064083417257\n",
      "51\n",
      "Epoch 51: Loss 3.11980934937795\n",
      "52\n",
      "Epoch 52: Loss 3.2691806157430015\n",
      "53\n",
      "Epoch 53: Loss 3.2455927530924478\n",
      "54\n",
      "Epoch 54: Loss 3.294057250022888\n",
      "55\n",
      "Epoch 55: Loss 3.3266636530558267\n",
      "56\n",
      "Epoch 56: Loss 3.1264915466308594\n",
      "57\n",
      "Epoch 57: Loss 3.103043874104818\n",
      "58\n",
      "Epoch 58: Loss 3.176877419153849\n",
      "59\n",
      "Epoch 59: Loss 3.172000288963318\n",
      "60\n",
      "Epoch 60: Loss 3.2855101426442466\n",
      "61\n",
      "Epoch 61: Loss 3.2403310537338257\n",
      "62\n",
      "Epoch 62: Loss 3.0910794138908386\n",
      "63\n",
      "Epoch 63: Loss 3.1841113567352295\n",
      "64\n",
      "Epoch 64: Loss 3.1986470222473145\n",
      "65\n",
      "Epoch 65: Loss 3.070062041282654\n",
      "66\n",
      "Epoch 66: Loss 3.435969670613607\n",
      "67\n",
      "Epoch 67: Loss 3.1621283292770386\n",
      "68\n",
      "Epoch 68: Loss 3.112795829772949\n",
      "69\n",
      "Epoch 69: Loss 3.066933790842692\n",
      "70\n",
      "Epoch 70: Loss 3.082017103830973\n",
      "71\n",
      "Epoch 71: Loss 3.124284029006958\n",
      "72\n",
      "Epoch 72: Loss 3.0700775384902954\n",
      "73\n",
      "Epoch 73: Loss 3.1264606714248657\n",
      "74\n",
      "Epoch 74: Loss 3.107361912727356\n",
      "75\n",
      "Epoch 75: Loss 3.1047404209772744\n",
      "76\n",
      "Epoch 76: Loss 3.321978529294332\n",
      "77\n",
      "Epoch 77: Loss 3.0530057748158774\n",
      "78\n",
      "Epoch 78: Loss 3.0536109606424966\n",
      "79\n",
      "Epoch 79: Loss 3.0394994815190635\n",
      "80\n",
      "Epoch 80: Loss 3.1381556193033853\n",
      "81\n",
      "Epoch 81: Loss 3.256467898686727\n",
      "82\n",
      "Epoch 82: Loss 3.3105948766072593\n",
      "83\n",
      "Epoch 83: Loss 3.772550384203593\n",
      "84\n",
      "Epoch 84: Loss 3.4304474194844565\n",
      "85\n",
      "Epoch 85: Loss 3.2283820708592734\n",
      "86\n",
      "Epoch 86: Loss 3.164403756459554\n",
      "87\n",
      "Epoch 87: Loss 3.0972095330556235\n",
      "88\n",
      "Epoch 88: Loss 3.2775751749674478\n",
      "89\n",
      "Epoch 89: Loss 3.0977203845977783\n",
      "90\n",
      "Epoch 90: Loss 3.219520608584086\n",
      "91\n",
      "Epoch 91: Loss 3.1276530027389526\n",
      "92\n",
      "Epoch 92: Loss 3.3865002393722534\n",
      "93\n",
      "Epoch 93: Loss 3.353099743525187\n",
      "94\n",
      "Epoch 94: Loss 3.162959893544515\n",
      "95\n",
      "Epoch 95: Loss 3.1373854875564575\n",
      "96\n",
      "Epoch 96: Loss 3.2639025847117105\n",
      "97\n",
      "Epoch 97: Loss 2.989701509475708\n",
      "98\n",
      "Epoch 98: Loss 3.2725494702657065\n",
      "99\n",
      "Epoch 99: Loss 3.280288338661194\n"
     ]
    }
   ],
   "source": [
    "model = SimpleRamanCNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss=0\n",
    "    print(epoch)\n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch}: Loss {running_loss/len(loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3a983853",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test=np.array(clean_test,dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4916e0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.936371 , 1.540566 , 2.2048864],\n",
       "       [8.952938 , 1.5425146, 2.2084045],\n",
       "       [8.439057 , 1.4874697, 2.09876  ],\n",
       "       [8.44164  , 1.487784 , 2.0993133],\n",
       "       [8.980466 , 1.5454786, 2.214272 ],\n",
       "       [8.99685  , 1.547246 , 2.2177715],\n",
       "       [8.923221 , 1.5391525, 2.2020707],\n",
       "       [8.9418125, 1.5412496, 2.2060356],\n",
       "       [8.788187 , 1.525033 , 2.1732404],\n",
       "       [8.784266 , 1.5246392, 2.1723998],\n",
       "       [9.054694 , 1.553712 , 2.2300875],\n",
       "       [9.080652 , 1.5564604, 2.2356362],\n",
       "       [8.78356  , 1.5242577, 2.172273 ],\n",
       "       [8.689324 , 1.5141853, 2.1521702],\n",
       "       [9.055243 , 1.5537729, 2.2302017],\n",
       "       [9.098289 , 1.5583899, 2.239393 ],\n",
       "       [7.0439706, 1.3376766, 1.8014987],\n",
       "       [7.046061 , 1.3379481, 1.8019707],\n",
       "       [8.938761 , 1.5412221, 2.2053618],\n",
       "       [9.119444 , 1.5607653, 2.243912 ],\n",
       "       [6.7192464, 1.3028827, 1.7323984],\n",
       "       [6.7528043, 1.3063418, 1.7395462],\n",
       "       [6.6134257, 1.2916512, 1.7098716],\n",
       "       [6.6292496, 1.2932996, 1.7132387],\n",
       "       [6.425043 , 1.2716813, 1.6697776],\n",
       "       [6.436251 , 1.2727739, 1.6721877],\n",
       "       [6.4589067, 1.2753861, 1.6769685],\n",
       "       [6.4400163, 1.2731255, 1.6729804],\n",
       "       [6.3664055, 1.2653944, 1.6573094],\n",
       "       [6.3969545, 1.2686231, 1.6638297],\n",
       "       [6.381821 , 1.266965 , 1.6605828],\n",
       "       [6.3962293, 1.2683897, 1.6636531],\n",
       "       [6.2655473, 1.2547139, 1.6358927],\n",
       "       [6.264345 , 1.2545317, 1.635642 ],\n",
       "       [6.2039485, 1.2482922, 1.6228161],\n",
       "       [6.2429996, 1.2522306, 1.6311187],\n",
       "       [6.2082996, 1.2486463, 1.6237257],\n",
       "       [6.2059174, 1.2483215, 1.623228 ],\n",
       "       [6.0711226, 1.2342323, 1.5945984],\n",
       "       [6.0680237, 1.2337844, 1.5939407],\n",
       "       [6.084727 , 1.2355431, 1.597492 ],\n",
       "       [6.088952 , 1.2360098, 1.5983821],\n",
       "       [6.0677547, 1.2337512, 1.593862 ],\n",
       "       [6.0878234, 1.2358555, 1.5981437],\n",
       "       [8.888879 , 1.5354397, 2.1947446],\n",
       "       [8.930548 , 1.5398915, 2.2036514],\n",
       "       [5.7296004, 1.1981333, 1.5220118],\n",
       "       [5.71306  , 1.1962909, 1.5185175],\n",
       "       [6.2040815, 1.2481954, 1.622852 ],\n",
       "       [6.210058 , 1.2487137, 1.6241283],\n",
       "       [6.1932373, 1.2470721, 1.6205404],\n",
       "       [6.231963 , 1.251297 , 1.6287495],\n",
       "       [6.1044564, 1.2375015, 1.6016726],\n",
       "       [6.08901  , 1.2358861, 1.5983964],\n",
       "       [6.0132947, 1.2280334, 1.5822914],\n",
       "       [6.056626 , 1.2326723, 1.5915126],\n",
       "       [6.022736 , 1.2290857, 1.5842935],\n",
       "       [6.0362706, 1.2304085, 1.5871876],\n",
       "       [8.896985 , 1.5364162, 2.1964767],\n",
       "       [8.955432 , 1.5427293, 2.2089386],\n",
       "       [6.3073378, 1.2590977, 1.644764 ],\n",
       "       [6.345375 , 1.2632164, 1.6528398],\n",
       "       [9.007039 , 1.5484599, 2.2199268],\n",
       "       [9.056129 , 1.5538775, 2.2304058],\n",
       "       [7.008306 , 1.333825 , 1.7939286],\n",
       "       [7.095355 , 1.3431695, 1.8124946],\n",
       "       [6.959409 , 1.3284929, 1.783509 ],\n",
       "       [6.990303 , 1.3317899, 1.7901098],\n",
       "       [8.954096 , 1.5426699, 2.2086434],\n",
       "       [9.072055 , 1.555541 , 2.233811 ],\n",
       "       [8.884152 , 1.5351197, 2.1937397],\n",
       "       [8.994325 , 1.5469562, 2.2172387],\n",
       "       [8.986889 , 1.5462717, 2.2156425],\n",
       "       [9.060293 , 1.5543257, 2.2313013],\n",
       "       [7.1363378, 1.3476136, 1.8211775],\n",
       "       [7.227371 , 1.357277 , 1.8405708],\n",
       "       [7.115006 , 1.345129 , 1.8166487],\n",
       "       [7.1405845, 1.3478767, 1.822108 ],\n",
       "       [7.1378417, 1.3476835, 1.8214983],\n",
       "       [7.2171044, 1.356285 , 1.8383824],\n",
       "       [6.461524 , 1.2755506, 1.6775442],\n",
       "       [6.50387  , 1.2798301, 1.6865814],\n",
       "       [8.897179 , 1.5363039, 2.1965249],\n",
       "       [8.962392 , 1.5434229, 2.2104344],\n",
       "       [8.89118  , 1.5359529, 2.1952267],\n",
       "       [9.00758  , 1.548452 , 2.220059 ],\n",
       "       [8.925492 , 1.5394621, 2.2025447],\n",
       "       [8.914204 , 1.5381933, 2.2001626],\n",
       "       [8.879653 , 1.5344274, 2.1927907],\n",
       "       [8.897231 , 1.5364128, 2.196545 ],\n",
       "       [8.511199 , 1.4950408, 2.1141942],\n",
       "       [8.635158 , 1.5083778, 2.1406424],\n",
       "       [8.491565 , 1.4925965, 2.1100402],\n",
       "       [8.532061 , 1.4970577, 2.1186671],\n",
       "       [6.5474076, 1.2843983, 1.6958548],\n",
       "       [6.5848527, 1.2883948, 1.7038282],\n",
       "       [5.933957 , 1.2196478, 1.5654504],\n",
       "       [5.9614854, 1.2224091, 1.5713027],\n",
       "       [8.961427 , 1.5433638, 2.210232 ],\n",
       "       [9.020265 , 1.5498092, 2.2227733],\n",
       "       [8.832561 , 1.5293491, 2.1827514],\n",
       "       [8.920421 , 1.5388459, 2.201494 ],\n",
       "       [5.740153 , 1.1989971, 1.5242826],\n",
       "       [5.724077 , 1.1973233, 1.520872 ],\n",
       "       [5.71436  , 1.1963446, 1.5188041],\n",
       "       [5.732327 , 1.1984361, 1.5225906],\n",
       "       [8.89282  , 1.5358579, 2.195602 ],\n",
       "       [8.96294  , 1.5434747, 2.2105715],\n",
       "       [5.5913444, 1.1832182, 1.4926908],\n",
       "       [5.5811195, 1.1819453, 1.4905293],\n",
       "       [8.856875 , 1.5320352, 2.1879323],\n",
       "       [8.987583 , 1.5461534, 2.2158172],\n",
       "       [8.940551 , 1.541083 , 2.2057884],\n",
       "       [9.010005 , 1.5486906, 2.2205849],\n",
       "       [8.9104185, 1.5378757, 2.1993515],\n",
       "       [8.960916 , 1.5433385, 2.2101321],\n",
       "       [8.861289 , 1.5325326, 2.188883 ],\n",
       "       [8.988821 , 1.5463932, 2.216074 ],\n",
       "       [7.862385 , 1.4255093, 1.9758782],\n",
       "       [7.899374 , 1.4294873, 1.9837605],\n",
       "       [7.7554827, 1.4139504, 1.9530988],\n",
       "       [7.8023186, 1.4187652, 1.9630907],\n",
       "       [7.6584373, 1.4035743, 1.9323927],\n",
       "       [7.6812778, 1.4061049, 1.9372916],\n",
       "       [6.5613194, 1.2860296, 1.698808 ],\n",
       "       [6.5489845, 1.2845803, 1.69619  ],\n",
       "       [6.5500937, 1.2848606, 1.6964065],\n",
       "       [6.6144643, 1.291634 , 1.7101201],\n",
       "       [8.761646 , 1.5219295, 2.1676226],\n",
       "       [8.870339 , 1.5338609, 2.190771 ],\n",
       "       [8.894524 , 1.5361727, 2.1959565],\n",
       "       [9.015077 , 1.549331 , 2.2216656],\n",
       "       [6.842064 , 1.3160826, 1.7585254],\n",
       "       [6.8960195, 1.3216451, 1.7700485],\n",
       "       [6.7868357, 1.3101048, 1.7467608],\n",
       "       [6.783588 , 1.3098495, 1.7460713],\n",
       "       [6.748045 , 1.3058794, 1.7385565],\n",
       "       [6.821419 , 1.3136653, 1.7541765],\n",
       "       [6.6185255, 1.2921216, 1.7109647],\n",
       "       [6.651045 , 1.2954922, 1.717895 ],\n",
       "       [6.558886 , 1.2857455, 1.6982815],\n",
       "       [6.611697 , 1.291261 , 1.7095351],\n",
       "       [6.547536 , 1.2846189, 1.6958504],\n",
       "       [6.588472 , 1.2890085, 1.7045872],\n",
       "       [5.62833  , 1.1873411, 1.5005511],\n",
       "       [5.642531 , 1.1887339, 1.5035665],\n",
       "       [8.887316 , 1.5354302, 2.1944237],\n",
       "       [9.026524 , 1.550579 , 2.2241073],\n",
       "       [5.6539774, 1.1900607, 1.5059935],\n",
       "       [5.686598 , 1.1934533, 1.5129207],\n",
       "       [8.951263 , 1.5423583, 2.2080684],\n",
       "       [8.975594 , 1.5449426, 2.2132592],\n",
       "       [8.824423 , 1.5283889, 2.1810262],\n",
       "       [8.907545 , 1.5374489, 2.1987674],\n",
       "       [5.8336062, 1.209131 , 1.5441417],\n",
       "       [5.8452644, 1.2102389, 1.5466306],\n",
       "       [8.848071 , 1.5309504, 2.186072 ],\n",
       "       [8.905428 , 1.5372257, 2.1983006],\n",
       "       [8.883968 , 1.5349184, 2.1937265],\n",
       "       [8.928868 , 1.5397015, 2.2033103],\n",
       "       [8.229203 , 1.4647456, 2.054075 ],\n",
       "       [8.296341 , 1.4719692, 2.068405 ],\n",
       "       [8.06283  , 1.4467052, 2.0186172],\n",
       "       [8.142169 , 1.4551592, 2.035543 ],\n",
       "       [7.7298274, 1.4112835, 1.9476246],\n",
       "       [7.793656 , 1.4181566, 1.9612308],\n",
       "       [8.904418 , 1.5373683, 2.1980557],\n",
       "       [8.970995 , 1.5445286, 2.2122638],\n",
       "       [8.841802 , 1.5304815, 2.18472  ],\n",
       "       [8.9503565, 1.5421503, 2.2078736],\n",
       "       [6.392016 , 1.2680821, 1.6627816],\n",
       "       [6.409758 , 1.2698022, 1.6665574],\n",
       "       [6.363849 , 1.2648782, 1.6567862],\n",
       "       [6.413063 , 1.2701317, 1.6672552],\n",
       "       [6.3385353, 1.2623334, 1.6514039],\n",
       "       [6.33076  , 1.2613981, 1.6497738],\n",
       "       [6.3134685, 1.2597531, 1.6460911],\n",
       "       [6.3501887, 1.2638321, 1.6538368],\n",
       "       [6.0477386, 1.2316704, 1.5896422],\n",
       "       [6.0640883, 1.2332526, 1.593117 ],\n",
       "       [5.9880934, 1.2254378, 1.5769607],\n",
       "       [5.998883 , 1.2263417, 1.57925  ],\n",
       "       [5.9398065, 1.2204355, 1.5666802],\n",
       "       [5.933736 , 1.2195684, 1.5654061],\n",
       "       [8.884148 , 1.5349805, 2.1937554],\n",
       "       [8.959725 , 1.5431161, 2.2098825],\n",
       "       [8.911151 , 1.5379422, 2.199515 ],\n",
       "       [8.939646 , 1.5410217, 2.205596 ],\n",
       "       [8.8114805, 1.5270654, 2.178268 ],\n",
       "       [8.921015 , 1.5388514, 2.2016306],\n",
       "       [8.920004 , 1.5388502, 2.2014022],\n",
       "       [8.978669 , 1.5452375, 2.213918 ]], dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(RamanDataset(clean_test,None, train=False), batch_size=32, shuffle=False)\n",
    "sanity_check= DataLoader(RamanDataset(interpolated,None, train=False), batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()  # switch to evaluation mode\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for spectra in test_loader:\n",
    "        outputs = model(spectra)  # shape (batch, 3)\n",
    "        predictions.append(outputs)\n",
    "\n",
    "predictions = torch.cat(predictions).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "bbba96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load predictions to sample_submission.csv\n",
    "\n",
    "template= pd.read_csv(\"test/sample_submission.csv\")\n",
    "\n",
    "\n",
    "averaged = predictions.reshape(-1, 2, 3).mean(axis=1)\n",
    "\n",
    "template[['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']] = averaged\n",
    "\n",
    "# Save to new CSV\n",
    "template.to_csv(\"test/sample_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5c0ab",
   "metadata": {},
   "source": [
    "Now we apply CV to fine tune hiperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b7928e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Fold 1/5 ----\n",
      "Epoch 1/10 - Val Loss: 4.2600\n",
      "Epoch 2/10 - Val Loss: 4.2167\n",
      "Epoch 3/10 - Val Loss: 4.2029\n",
      "Epoch 4/10 - Val Loss: 4.1979\n",
      "Epoch 5/10 - Val Loss: 4.2144\n",
      "Epoch 6/10 - Val Loss: 4.2025\n",
      "Epoch 7/10 - Val Loss: 4.2062\n",
      "Epoch 8/10 - Val Loss: 4.2229\n",
      "Epoch 9/10 - Val Loss: 4.1969\n",
      "Epoch 10/10 - Val Loss: 4.2205\n",
      "\n",
      "---- Fold 2/5 ----\n",
      "Epoch 1/10 - Val Loss: 4.4577\n",
      "Epoch 2/10 - Val Loss: 4.4764\n",
      "Epoch 3/10 - Val Loss: 4.4408\n",
      "Epoch 4/10 - Val Loss: 4.4466\n",
      "Epoch 5/10 - Val Loss: 4.4281\n",
      "Epoch 6/10 - Val Loss: 4.4366\n",
      "Epoch 7/10 - Val Loss: 4.4584\n",
      "Epoch 8/10 - Val Loss: 4.4637\n",
      "Epoch 9/10 - Val Loss: 4.4088\n",
      "Epoch 10/10 - Val Loss: 4.4349\n",
      "\n",
      "---- Fold 3/5 ----\n",
      "Epoch 1/10 - Val Loss: 3.9646\n",
      "Epoch 2/10 - Val Loss: 3.9816\n",
      "Epoch 3/10 - Val Loss: 3.9581\n",
      "Epoch 4/10 - Val Loss: 3.9908\n",
      "Epoch 5/10 - Val Loss: 3.9772\n",
      "Epoch 6/10 - Val Loss: 3.9952\n",
      "Epoch 7/10 - Val Loss: 3.9418\n",
      "Epoch 8/10 - Val Loss: 3.9505\n",
      "Epoch 9/10 - Val Loss: 3.9339\n",
      "Epoch 10/10 - Val Loss: 3.9453\n",
      "\n",
      "---- Fold 4/5 ----\n",
      "Epoch 1/10 - Val Loss: 4.0549\n",
      "Epoch 2/10 - Val Loss: 4.0257\n",
      "Epoch 3/10 - Val Loss: 4.0359\n",
      "Epoch 4/10 - Val Loss: 4.0226\n",
      "Epoch 5/10 - Val Loss: 4.0202\n",
      "Epoch 6/10 - Val Loss: 4.0258\n",
      "Epoch 7/10 - Val Loss: 4.0349\n",
      "Epoch 8/10 - Val Loss: 4.0282\n",
      "Epoch 9/10 - Val Loss: 4.0221\n",
      "Epoch 10/10 - Val Loss: 4.0250\n",
      "\n",
      "---- Fold 5/5 ----\n",
      "Epoch 1/10 - Val Loss: 4.2690\n",
      "Epoch 2/10 - Val Loss: 4.2536\n",
      "Epoch 3/10 - Val Loss: 4.2621\n",
      "Epoch 4/10 - Val Loss: 4.2571\n",
      "Epoch 5/10 - Val Loss: 4.2530\n",
      "Epoch 6/10 - Val Loss: 4.2385\n",
      "Epoch 7/10 - Val Loss: 4.2389\n",
      "Epoch 8/10 - Val Loss: 4.2612\n",
      "Epoch 9/10 - Val Loss: 4.2601\n",
      "Epoch 10/10 - Val Loss: 4.2580\n",
      "\n",
      "Average Val Loss across folds: 4.1768\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# === Your Dataset Class ===\n",
    "class RamanDataset(Dataset):\n",
    "    def __init__(self, spectra, targets, augment=False):\n",
    "        self.spectra = spectra  # Tensor: shape [N, length]\n",
    "        self.targets = targets  # Tensor: shape [N]\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.spectra)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spectrum = self.spectra[idx]\n",
    "        label = self.targets[idx]\n",
    "\n",
    "        if self.augment:\n",
    "            spectrum = spectrum + sinusoidal_noise(len(spectrum))  # your noise fn\n",
    "            spectrum = left_right_shift(torch.linspace(300,1940,1340), spectrum, maxshift=5)  # example\n",
    "\n",
    "        spectrum = spectrum.unsqueeze(0)\n",
    "\n",
    "        return spectrum, label\n",
    "\n",
    "\n",
    "# === K-fold cross validation setup ===\n",
    "def run_kfold_cv(spectra, targets, k=5, batch_size=32, epochs=10):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    all_val_losses = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(spectra)):\n",
    "        print(f\"\\n---- Fold {fold+1}/{k} ----\")\n",
    "\n",
    "\n",
    "        train_dataset = RamanDataset(spectra[train_idx], targets[train_idx], augment=True)\n",
    "        val_dataset   = RamanDataset(spectra[val_idx], targets[val_idx], augment=False)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Create model\n",
    "        model = SimpleRamanCNN()  # replace with your model class\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for X, y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                out = model(X)\n",
    "                loss = criterion(out, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for X, y in val_loader: \n",
    "                    out = model(X)\n",
    "                    val_loss += criterion(out, y).item()\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        all_val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"\\nAverage Val Loss across folds: {sum(all_val_losses)/len(all_val_losses):.4f}\")\n",
    "\n",
    "\n",
    "# === Example call ===\n",
    "# spectra, targets = your Raman data as tensors\n",
    "# wavelengths = your x-axis tensor for augmentation\n",
    "\n",
    "spectra = torch.tensor(interpolated, dtype=torch.float32)\n",
    "targets = torch.tensor(conc, dtype=torch.float32)\n",
    "run_kfold_cv(spectra, targets, k=5, batch_size=32, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
